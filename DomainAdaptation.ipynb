{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpLam5ZsNHBV"
      },
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "from sklearn.model_selection import StratifiedShuffleSplit"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-MTwaG5aVmj"
      },
      "source": [
        "DEVICE = 'cuda'\n",
        "NUM_CLASSES= 7\n",
        "BATCH_SIZE = 128\n",
        "LR=1e-4\n",
        "MOMENTUM= 0.9\n",
        "WEIGHT_DECAY = 5e-5\n",
        "\n",
        "NUM_EPOCHS=30\n",
        "STEP_SIZE=20\n",
        "GAMMA= 0.1\n",
        "\n",
        "LOG_FREQUENCY=10\n",
        "ALPHA=0.5\n",
        "cross_val_domain=True\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_KD9knTH6g7"
      },
      "source": [
        "alexNet_transform = transforms.Compose([\n",
        "                                      transforms.CenterCrop(224),\n",
        "                                      transforms.ToTensor(),\n",
        "                                      transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))\n",
        "                                            ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8irSMj8d79n8"
      },
      "source": [
        "from torchvision.datasets import VisionDataset, ImageFolder\n",
        "from PIL import Image\n",
        "import os\n",
        "import os.path\n",
        "import sys\n",
        "import shutil\n",
        "import numpy as np\n",
        "\n",
        "# Clone github repository with data\n",
        "if not os.path.isdir('./PACS'):\n",
        "  !git clone https://github.com/MachineLearning2020/Homework3-PACS\n",
        "  !mv 'Homework3-PACS' 'PACS'\n",
        "  \n",
        "  \n",
        "\n",
        "DATA_DIR = 'PACS/PACS'\n",
        "\n",
        "\n",
        "def pil_loader(path):\n",
        "  \n",
        "  #path=path.rstrip(\"\\n\")\n",
        "  with open(path, 'rb') as f:\n",
        "    img=Image.open(f)\n",
        "    return img.convert('RGB')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Pacs(VisionDataset):\n",
        "    def __init__(self, root, split='', transform=None, target_transform=None):\n",
        "        \n",
        "        \n",
        "        self.split = split\n",
        "        self.root = os.path.join(root,self.split)\n",
        "        #print(self.root)\n",
        "        self.transform = transform\n",
        "        \n",
        "\n",
        "        self.dataset= []\n",
        "\n",
        "        self.dataset = ImageFolder(self.root, transform=transform, loader=pil_loader)\n",
        "        print(self.dataset[2])\n",
        "        print(len(self.dataset))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "      \n",
        "      return self.dataset[index]\n",
        "\n",
        "    def __len__(self):\n",
        "      return len(self.dataset)\n",
        "          \n",
        "\n",
        "art_painting=Pacs(DATA_DIR, 'art_painting', transform=alexNet_transform)\n",
        "cartoon=Pacs(DATA_DIR, 'cartoon', transform=alexNet_transform)\n",
        "photo=Pacs(DATA_DIR, 'photo', transform=alexNet_transform)\n",
        "sketch=Pacs(DATA_DIR, 'sketch', transform=alexNet_transform)\n",
        "\n",
        "#photoValidation= photo.dataset.samples[:, len(photo)-200:len(photo)]\n",
        "\n",
        "#print(sketch.__getitem__(2))\n",
        "\n",
        "print(\".sketch\",sketch.__len__)\n",
        "print(\"phptp\",photo.__len__)\n",
        "print(\"cartoon\",cartoon.__len__)\n",
        "print(\"art\",art_painting.__len__)\n",
        "\n",
        "def imgshow(img, mean=None, std=None):\n",
        "\tif mean == None or std == None:\n",
        "\t\t# use (0.5 0.5 0.5) (0.5 0.5 0.5) as mean and std\n",
        "\t\timg = img / 2 + 0.5     # unnormalize\n",
        "\t\tnpimg = img.numpy()\n",
        "\t\tplt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\t\tplt.show()\n",
        "\t\t# raise RuntimeError(\"You should pass mean and std to 'imgshow' method\")\n",
        "\telse : \n",
        "\t\t# use custom mean and std computed on the images\n",
        "\t\tmean = np.array(mean)\n",
        "\t\tstd = np.array(std)\n",
        "\t\tfor i in range(3): \n",
        "\t\t\timg[i] = img[i]*std[i] + mean[i] # unnormalize\n",
        "\n",
        "\t\tnpimg = img.numpy()\n",
        "\t\tplt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "\t\tplt.show()\n",
        "\treturn\n",
        "\n",
        "\n",
        "class0=0\n",
        "class1=0\n",
        "class2=0\n",
        "class3=0\n",
        "class4=0\n",
        "class5=0\n",
        "class6=0\n",
        "\n",
        "leng= len(photo)\n",
        "for i in range(leng):\n",
        "  if sketch.dataset.targets[i] == 0:\n",
        "    class0= class0+1\n",
        "    imgshow(art_painting.dataset[i][0])\n",
        "  elif photo.dataset.targets[i] == 1:\n",
        "    class1= class1+1\n",
        "  elif photo.dataset.targets[i] == 2:\n",
        "     class2=class2 + 1\n",
        "  elif photo.dataset.targets[i] == 3:\n",
        "      class3= class3+1 \n",
        "  elif photo.dataset.targets[i] == 4:\n",
        "     class4= class4+1\n",
        "  elif photo.dataset.targets[i] == 5:\n",
        "     class5 = class5+1\n",
        "  elif photo.dataset.targets[i] == 6:\n",
        "     class6 = class6+1\n",
        "\n",
        "\n",
        "print(class0, class1, class2, class3, class4, class5, class6)\n",
        "#print(photo.dataset.class_to_idx)\n",
        "print(class0 + class1 + class2 + class3 + class4 + class5 + class6)\n",
        "'''\n",
        "\n",
        "sss = StratifiedShuffleSplit(n_splits=1, test_size=0.1)\n",
        "\n",
        "train_indexes = [] # split the indices for your train split\n",
        "val_indexes = [] #split the indices for your val split\n",
        "\n",
        "\n",
        "\n",
        "for train, val in sss.split(photo.dataset.samples, photo.dataset.targets):\n",
        "  print(\"train-----\",train)\n",
        "  print(\"test-----\",val)\n",
        "  train_indexes=train\n",
        "  val_indexes=val\n",
        "\n",
        "photo_val=Subset(photo, val_indexes)\n",
        "photo= Subset(photo, train_indexes)\n",
        "\n",
        "print(len(photo))\n",
        "print(len(photo_val))\n",
        "'''\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dov0w9inr1el"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fj1qDVtfIG7q"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gg4UJad_WV97"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aS3-mdT5J8EU"
      },
      "source": [
        "# Dataloaders iterate over pytorch datasets and transparently provide useful functions (e.g. parallelization and shuffling)\n",
        "from torchvision import utils\n",
        "import matplotlib.pyplot as plt\n",
        "#print(cartoon[0])\n",
        "\n",
        "cartoon_dataloader = DataLoader(cartoon, batch_size=1, shuffle=True, num_workers=4, drop_last=True)\n",
        "art_painting_dataloader = DataLoader(art_painting, batch_size=1, shuffle=True, num_workers=4, drop_last=True)\n",
        "photo_dataloader = DataLoader(photo, batch_size=1, shuffle=True, num_workers=4, drop_last=True)\n",
        "sketch_dataloader = DataLoader(sketch, batch_size=1, shuffle=True, num_workers=4, drop_last=True)\n",
        "\n",
        "#photo_val_dataloader = DataLoader(photo_val, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=False)\n",
        "#val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "#train_val_dataloader =  DataLoader(train_val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
        "\n",
        "xb, yb = next(iter(cartoon_dataloader))\n",
        "out = torchvision.utils.make_grid(xb)\n",
        "plt.imshow(out.numpy().transpose((1, 2, 0)))\n",
        "\n",
        "print(photo_dataloader.dataset[0])\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rhc_GpWK3Pg"
      },
      "source": [
        "import torch.nn as nn\n",
        "from torch.autograd import Function\n",
        "\n",
        "class ReverseLayerF(Function):\n",
        "    # Forwards identity\n",
        "    # Sends backward reversed gradients\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "\n",
        "        return x.view_as(x)\n",
        "        \n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "\n",
        "        return output, None\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8tCxa-SHwW2"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.hub import load_state_dict_from_url\n",
        "\n",
        "\n",
        "\n",
        "__all__ = ['AlexNet', 'alexnet']\n",
        "\n",
        "\n",
        "model_urls = {\n",
        "    'alexnet': 'https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth',\n",
        "}\n",
        "\n",
        "\n",
        "class AlexNet(nn.Module):\n",
        "\n",
        "    def __init__(self, num_classes=1000):\n",
        "        super(AlexNet, self).__init__()\n",
        "        self.features = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=11, stride=4, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "            nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=3, stride=2),\n",
        "        )\n",
        "        self.avgpool = nn.AdaptiveAvgPool2d((6, 6))\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(256 * 6 * 6, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(4096, 4096),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Linear(4096, num_classes)\n",
        "            \n",
        "        )\n",
        "\n",
        "        self.domainClassifier1 = nn.Sequential(\n",
        "          nn.Dropout(),\n",
        "          nn.Linear(256 * 6 * 6, 4096),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Dropout(),\n",
        "          nn.Linear(4096, 4096),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Linear(4096, 2)\n",
        "          \n",
        "        )\n",
        "\n",
        "        self.domainClassifier = nn.Sequential(\n",
        "          nn.Dropout(),\n",
        "          nn.Linear(256 * 6 * 6, 4096),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Dropout(),\n",
        "          nn.Linear(4096, 4096),\n",
        "          nn.ReLU(inplace=True),\n",
        "          nn.Linear(4096, 2)\n",
        "          \n",
        "        )\n",
        "\n",
        "    def conv (self, x):\n",
        "      x = self.features(x)\n",
        "      return x\n",
        "\n",
        "    def forward(self, x, alpha=None):\n",
        "        #print(x.size())\n",
        "        features = self.features(x)\n",
        "        features = self.avgpool(features)\n",
        "\n",
        "        #print(\"before view avgPool\",features.size()) #([1, 256, 6, 6])\n",
        "        features = features.view(features.size(0), -1) \n",
        "        #print(\"after view\",features.size()) #([1, 9216])\n",
        "\n",
        "        if alpha is not None:\n",
        "          reverse_feature = ReverseLayerF.apply(features, alpha)\n",
        "          #print(\"rf size\",reverse_feature.size())  #([1, 9216])   \n",
        "          discriminator_output = self.domainClassifier1(reverse_feature)\n",
        "          return discriminator_output\n",
        "        else:\n",
        "          x = self.classifier(features)\n",
        "          return x\n",
        "\n",
        "\n",
        "def alexnet(pretrained=False, progress=True, **kwargs):\n",
        "    r\"\"\"AlexNet model architecture from the\n",
        "    `\"One weird trick...\" <https://arxiv.org/abs/1404.5997>`_ paper.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "        progress (bool): If True, displays a progress bar of the download to stderr\n",
        "    \"\"\"\n",
        "    model = AlexNet(**kwargs)\n",
        "    if pretrained:\n",
        "        state_dict = load_state_dict_from_url(model_urls['alexnet'],\n",
        "                                              progress=progress)\n",
        "        model.load_state_dict(state_dict, strict=False)\n",
        "    return model\n",
        "\n",
        "\n",
        "net=alexnet(pretrained=True)\n",
        "net.classifier[6] = nn.Linear(4096, 7)\n",
        "\n",
        "weights=net.classifier[1].weight.data\n",
        "bias= net.classifier[1].bias.data\n",
        "\n",
        "\n",
        "net.domainClassifier1[1].weight.data = weights\n",
        "net.domainClassifier1[1].bias.data = bias\n",
        "print(net)\n",
        "'''\n",
        "print(net.features(photo.__getitem__(0)[0].unsqueeze(0)).size())\n",
        "#print(net.features(photo.__getitem__(0)[0].unsqueeze(0)))\n",
        "img= net.features(photo.__getitem__(0)[0].unsqueeze(0))\n",
        "img = net.avgpool(img)\n",
        "print(\"--------------\",img.size())\n",
        "img=net.forward(img, alpha=1)\n",
        "print(img.size())\n",
        "'''\n",
        "img=net.conv(photo.__getitem__(0)[0].unsqueeze(0))\n",
        "print(img.size())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V5iS27QpWqVI"
      },
      "source": [
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nyjkl_6paD-E"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8rPKpASagci"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nOLEpcuxatDA"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "parameters_to_optimize = net.parameters()\n",
        "\n",
        "optimizer = optim.SGD(parameters_to_optimize, lr=LR, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
        "\n",
        "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=STEP_SIZE, gamma=GAMMA)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hgpwJlvtXAfg"
      },
      "source": [
        "# train on photo and test on art painting without adaptation\n",
        "\n",
        "\n",
        "  \n",
        "accuracy_train=[]\n",
        "\n",
        "net = net.to(DEVICE)\n",
        "cudnn.benchmark\n",
        "\n",
        "\n",
        "current_step = 0\n",
        "loss_train=[]\n",
        "accuracy_test=[]\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "  print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "  running_corrects=0\n",
        "  for images, labels in photo_dataloader:\n",
        "    images=images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    net.train()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    outputs = net(images, alpha=None)\n",
        "    #print(\"outputssize\", outputs.size())\n",
        "    \n",
        "\n",
        "    loss= criterion(outputs, labels)\n",
        "\n",
        "    if current_step % LOG_FREQUENCY == 0:\n",
        "      print('Step {}, Loss {}'.format(current_step, loss.item()))\n",
        "\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    current_step += 1\n",
        "    scheduler.step()\n",
        "\n",
        "\n",
        "if cross_val_domain:\n",
        "  net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "  net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "  running_corrects = 0\n",
        "  for images, labels in cartoon_dataloader:\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy = running_corrects / float(len(cartoon))\n",
        "\n",
        "  print('Test Accuracy: {}'.format(accuracy))\n",
        "\n",
        "\n",
        "  running_corrects = 0\n",
        "  for images, labels in sketch_dataloader:\n",
        "    images = images.to(DEVICE)\n",
        "    labels = labels.to(DEVICE)\n",
        "\n",
        "    # Forward Pass\n",
        "    outputs = net(images)\n",
        "\n",
        "    # Get predictions\n",
        "    _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "    # Update Corrects\n",
        "    running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "  # Calculate Accuracy\n",
        "  accuracy_2 = running_corrects / float(len(sketch))\n",
        "\n",
        "  print('Test Accuracy: {}'.format(accuracy_2))\n",
        "    \n",
        "print(\"average accuracy: \", (accuracy + accuracy_2)/2)\n",
        " \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-km75yknNpVg"
      },
      "source": [
        "print(accuracy)\n",
        "print(len(loss_train))\n",
        "plt.plot(loss_train, label='Training Loss')\n",
        "\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Loss')\n",
        "#plt.ylim([0,1.0])\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lt4GPjsxiEEh"
      },
      "source": [
        "plt.plot(loss1, label=\"LR=0.01\")\n",
        "plt.plot(loss2, label=\"LR=0.001\")\n",
        "plt.plot(loss3, label=\"LR=0.0001\")\n",
        "plt.legend(loc='upper right')\n",
        "plt.ylabel('Loss')\n",
        "plt.ylim([-0.001,0.02])\n",
        "plt.title('Training Loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.grid()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIRbkHINGp9s"
      },
      "source": [
        "# domain adaptation with DANN\n",
        "net = net.to(DEVICE)\n",
        "cudnn.benchmark\n",
        "loss_1=[]\n",
        "loss_2=[]\n",
        "loss_3=[]\n",
        "\n",
        "\n",
        "current_step=0\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "   print('Starting epoch {}/{}, LR = {}'.format(epoch+1, NUM_EPOCHS, scheduler.get_lr()))\n",
        "\n",
        "   running_corrects=0\n",
        "\n",
        "   #len_dataloader = min(len(photo_dataloader), len(art_painting_dataloader))\n",
        "   #source = iter(photo_dataloader)\n",
        "   #target = iter(art_painting_dataloader)\n",
        "\n",
        "   for imgs_target,labels_target in sketch_dataloader:#range del target\n",
        "    \n",
        "     data_source = next(iter(photo_dataloader)) #prendo label del target\n",
        "     #target_source = target.next()\n",
        "\n",
        "     imgs_source, labels_source = data_source\n",
        "     #art_batch, art_labels = target_source\n",
        "\n",
        "     #print(\"PHOTO BATCH size\",photo_batch.size())\n",
        "     #print(\"photo_batch labels size\", photo_labels.size())\n",
        "\n",
        "     imgs_source = imgs_source.to(DEVICE)\n",
        "     labels_source = labels_source.to(DEVICE)\n",
        "     imgs_target = imgs_target.to(DEVICE)\n",
        "     labels_target = labels_target.to(DEVICE)\n",
        "\n",
        "     net.train()\n",
        "\n",
        "     optimizer.zero_grad()\n",
        "\n",
        "     outputs_classifier = net(imgs_source, alpha=None)  #tensor of 128 rows and 7 columns, with the proability for each class\n",
        "     #print(\"putputeclass\",outputs_classifier.size())\n",
        "\n",
        "     loss1 = criterion(outputs_classifier, labels_source)\n",
        "     #print(\"loss\",loss1)\n",
        "     loss1.backward()\n",
        "     #print(\"oooooooooo\")\n",
        "     #print(photo_batch[0])\n",
        "\n",
        "     outputs_source_domain = net(imgs_source, alpha=ALPHA)\n",
        "     source_domain_labels = torch.zeros(len(outputs_source_domain))\n",
        "     source_domain_labels=source_domain_labels.long()\n",
        "     source_domain_labels=source_domain_labels.to(DEVICE)\n",
        "     \n",
        "     #print(\"size source domain\",outputs_source_domain.size())\n",
        "     #print(\"size source domain\",source_domain_labels.size())\n",
        "\n",
        "     loss2 = criterion(outputs_source_domain, source_domain_labels)\n",
        "     loss2.backward()\n",
        "    \n",
        "\n",
        "     outputs_targets_domain = net(imgs_target, alpha=ALPHA)\n",
        "     target_domain_labels = torch.ones(len(outputs_targets_domain))\n",
        "     target_domain_labels=target_domain_labels.long()\n",
        "     target_domain_labels=target_domain_labels.to(DEVICE)\n",
        "     loss3 = criterion(outputs_targets_domain, target_domain_labels)\n",
        "     loss3.backward()\n",
        "\n",
        "     if current_step % LOG_FREQUENCY == 0:\n",
        "       print('Step {}, Loss1 {}, Loss2 {}, Loss3 {}'.format(current_step, loss1.item(), loss2.item(), loss3.item()))\n",
        "\n",
        "     optimizer.step() # update weights based on accumulated gradients\n",
        "\n",
        "     current_step += 1\n",
        "   loss_1.append(loss1)\n",
        "   loss_2.append(loss2)\n",
        "   loss_3.append(loss3)\n",
        "   scheduler.step()\n",
        "   scheduler.step()\n",
        "\n",
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in sketch_dataloader:\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "   # Forward Pass\n",
        "  outputs = net(images)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(sketch))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))\n",
        "     \n",
        "\n",
        "print(loss_1)\n",
        "print(loss_2)\n",
        "print(loss_3)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rerYTxLVe8eG",
        "outputId": "0da227b3-0d94-439c-d142-822e8ad88f04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "net = net.to(DEVICE) # this will bring the network to GPU if DEVICE is cuda\n",
        "net.train(False) # Set Network to evaluation mode\n",
        "\n",
        "running_corrects = 0\n",
        "for images, labels in tqdm(sketch_dataloader):\n",
        "  images = images.to(DEVICE)\n",
        "  labels = labels.to(DEVICE)\n",
        "\n",
        "  # Forward Pass\n",
        "  outputs = net(images)\n",
        "\n",
        "  # Get predictions\n",
        "  _, preds = torch.max(outputs.data, 1)\n",
        "\n",
        "  # Update Corrects\n",
        "  running_corrects += torch.sum(preds == labels.data).data.item()\n",
        "\n",
        "# Calculate Accuracy\n",
        "accuracy = running_corrects / float(len(sketch))\n",
        "\n",
        "print('Test Accuracy: {}'.format(accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 15/15 [00:11<00:00,  1.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.1598371086790532\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C4E8vOIVZ_lK"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn import svm, datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import plot_confusion_matrix\n",
        "\n",
        "np.set_printoptions(precision=2)\n",
        "titles_options = [(\"Confusion matrix, without normalization\", None),\n",
        "                  (\"Normalized confusion matrix\", 'true')]\n",
        "X_test= art_painting.dataset.samples\n",
        "y_test=art_painting.dataset.targets\n",
        "for title, normalize in titles_options:\n",
        "    disp = plot_confusion_matrix(net, X_test, y_test,\n",
        "                                 display_labels=\"33\",\n",
        "                                 cmap=plt.cm.Blues,\n",
        "                                 normalize=normalize)\n",
        "    disp.ax_.set_title(title)\n",
        "\n",
        "    print(title)\n",
        "    print(disp.confusion_matrix)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}